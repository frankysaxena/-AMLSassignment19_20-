{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from scipy import misc\n",
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "# path = '/Users/fsaxena/Documents/UCL/Masters/IntroML1/AMLSassignment19_20/AMLS_19-20_SN14002056'\n",
    "path = '/home/fsaxena/amls/AMLSassignment19_20/AMLS_19-20_SN14002056'\n",
    "\n",
    "\n",
    "assignment_celeb = 'celeba'\n",
    "assignment_cartoon = 'cartoon_set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(path_to_root, assignment):\n",
    "    return pd.read_csv(path_to_root + '/Datasets/original_dataset_AMLS_19-20/' + assignment + '/labels.csv', sep='\\t')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_to_vector(file):\n",
    "    img = cv2.imread(file, cv2.IMREAD_UNCHANGED)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_img=path+'/Datasets/original_dataset_AMLS_19-20/'+assignment_cartoon+'/img/1.png'\n",
    "path_pre_img = path+'/Datasets/original_dataset_AMLS_19-20/'+assignment_celeb+'/img/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        ...,\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0]],\n",
       "\n",
       "       [[255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        ...,\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0]],\n",
       "\n",
       "       [[255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        ...,\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        ...,\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0]],\n",
       "\n",
       "       [[255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        ...,\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0]],\n",
       "\n",
       "       [[255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        ...,\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0],\n",
       "        [255, 255, 255,   0]]], dtype=uint8)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(convert_image_to_vector(path_to_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now need to add each raw pic to each part of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  img_name  gender  smiling\n",
      "0              0     0.jpg      -1        1\n",
      "1              1     1.jpg      -1        1\n",
      "2              2     2.jpg       1       -1\n",
      "3              3     3.jpg      -1       -1\n",
      "4              4     4.jpg      -1       -1\n",
      "...          ...       ...     ...      ...\n",
      "4995        4995  4995.jpg       1        1\n",
      "4996        4996  4996.jpg       1        1\n",
      "4997        4997  4997.jpg       1        1\n",
      "4998        4998  4998.jpg       1        1\n",
      "4999        4999  4999.jpg       1        1\n",
      "\n",
      "[5000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "celeb_dataframe = data_loader(path, assignment_celeb)\n",
    "print(celeb_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_Array = []\n",
    "for img_name in celeb_dataframe['img_name']:\n",
    "    img_vec = np.array(convert_image_to_vector(path_pre_img + img_name))\n",
    "    vec_Array.append(img_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dataset = vec_Array\n",
    "y_dataset = celeb_dataframe['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(data_Dict, columns = ['img_vec', 'gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "x, X_test, y, y_test = train_test_split(\n",
    "    x_dataset,\n",
    "    y_dataset,\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     x,\n",
    "#     y,\n",
    "#     test_size=0.25,\n",
    "#     shuffle=True,\n",
    "#     random_state=42,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage import color\n",
    "\n",
    "from skimage.feature import hog\n",
    "from skimage.io import imread\n",
    "from skimage.transform import rescale\n",
    " \n",
    "class RGB2GrayTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Convert an array of RGB images to grayscale\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self):\n",
    "        pass\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"returns itself\"\"\"\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"perform the transformation and return an array\"\"\"\n",
    "        return np.array([color.rgb2gray(img) for img in X])\n",
    " \n",
    " \n",
    "class HogTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Expects an array of 2d arrays (1 channel images)\n",
    "    Calculates hog features for each img\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self, y=None, orientations=9,\n",
    "                 pixels_per_cell=(8, 8),\n",
    "                 cells_per_block=(3, 3), block_norm='L2-Hys'):\n",
    "        self.y = y\n",
    "        self.orientations = orientations\n",
    "        self.pixels_per_cell = pixels_per_cell\n",
    "        self.cells_per_block = cells_per_block\n",
    "        self.block_norm = block_norm\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    " \n",
    "        def local_hog(X):\n",
    "            return hog(X,\n",
    "                       orientations=self.orientations,\n",
    "                       pixels_per_cell=self.pixels_per_cell,\n",
    "                       cells_per_block=self.cells_per_block,\n",
    "                       block_norm=self.block_norm)\n",
    " \n",
    "        try: # parallel\n",
    "            return np.array([local_hog(img) for img in X])\n",
    "        except:\n",
    "            return np.array([local_hog(img) for img in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of each transformer\n",
    "grayify = RGB2GrayTransformer()\n",
    "hogify = HogTransformer(\n",
    "    pixels_per_cell=(8, 8),\n",
    "    cells_per_block=(2,2),\n",
    "    orientations=9,\n",
    "    block_norm='L2-Hys'\n",
    ")\n",
    "scalify = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 19656)\n"
     ]
    }
   ],
   "source": [
    "# call fit_transform on each transform converting X_train step by step\n",
    "X_train_gray = grayify.fit_transform(X_train)\n",
    "X_train_hog = hogify.fit_transform(X_train_gray)\n",
    "X_train_prepared = scalify.fit_transform(X_train_hog)\n",
    " \n",
    "print(X_train_prepared.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
       "              power_t=0.5, random_state=42, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier(random_state=42, max_iter=1000, tol=1e-3, n_jobs = -1)\n",
    "sgd_clf.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val_gray = grayify.transform(X_val)\n",
    "# X_val_hog = hogify.transform(X_val_gray)\n",
    "# X_val_prepared = scalify.transform(X_val_hog)\n",
    "\n",
    "X_test_gray = grayify.transform(X_test)\n",
    "X_test_hog = hogify.transform(X_test_gray)\n",
    "X_test_prepared = scalify.transform(X_test_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False False  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n",
      "\n",
      "Percentage correct:  92.5\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = sgd_clf.predict(X_test_prepared)\n",
    "print(np.array(y_test_pred == y_test)[:25])\n",
    "print('')\n",
    "print('Percentage correct: ', 100*np.sum(y_test_pred == y_test)/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage correct:  92.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    " \n",
    "HOG_pipeline = Pipeline([\n",
    "    ('grayify', RGB2GrayTransformer()),\n",
    "    ('hogify', HogTransformer(\n",
    "        pixels_per_cell=(8, 8),\n",
    "        cells_per_block=(2,2),\n",
    "        orientations=9,\n",
    "        block_norm='L2-Hys')\n",
    "    ),\n",
    "    ('scalify', StandardScaler()),\n",
    "    ('classify', SGDClassifier(random_state=42, max_iter=1000, tol=1e-3))\n",
    "])\n",
    " \n",
    "clf = HOG_pipeline.fit(X_train, y_train)\n",
    "print('Percentage correct: ', 100*np.sum(clf.predict(X_test) == y_test)/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    " \n",
    "param_grid = [\n",
    "    {'hogify__orientations': [9],\n",
    "     'hogify__cells_per_block': [(3, 3)],\n",
    "     'hogify__pixels_per_cell': [(14, 14)],\n",
    "     'classify': [\n",
    "#          SGDClassifier(random_state=42, max_iter=1000, tol=1e-3),\n",
    "        svm.SVC(kernel='rbf', C=1),\n",
    "        svm.SVC(kernel='rbf', C=10),\n",
    "        svm.SVC(kernel='rbf', C=100)]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   9 | elapsed:  4.8min remaining:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:  8.7min finished\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(HOG_pipeline,\n",
    "                           param_grid,\n",
    "                           cv=3,\n",
    "                           n_jobs=-1,\n",
    "                           scoring='accuracy',\n",
    "                           verbose=1,\n",
    "                           return_train_score=True)\n",
    " \n",
    "grid_res = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('grayify', RGB2GrayTransformer()),\n",
       "                ('hogify',\n",
       "                 HogTransformer(block_norm='L2-Hys', cells_per_block=(3, 3),\n",
       "                                orientations=9, pixels_per_cell=(14, 14),\n",
       "                                y=None)),\n",
       "                ('scalify',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('classify',\n",
       "                 SVC(C=10, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_res.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9202518020809549"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_res.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classify': SVC(C=10, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "     decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "     max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "     tol=0.001, verbose=False),\n",
       " 'hogify__cells_per_block': (3, 3),\n",
       " 'hogify__orientations': 9,\n",
       " 'hogify__pixels_per_cell': (14, 14)}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_res.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage correct:  93.6\n"
     ]
    }
   ],
   "source": [
    "best_pred = grid_res.predict(X_test)\n",
    "print('Percentage correct: ', 100*np.sum(best_pred == y_test)/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    " \n",
    "def plot_confusion_matrix(cmx, vmax1=None, vmax2=None, vmax3=None):\n",
    "    cmx_norm = 100*cmx / cmx.sum(axis=1, keepdims=True)\n",
    "    cmx_zero_diag = cmx_norm.copy()\n",
    " \n",
    "    np.fill_diagonal(cmx_zero_diag, 0)\n",
    " \n",
    "    fig, ax = plt.subplots(ncols=3)\n",
    "    fig.set_size_inches(12, 3)\n",
    "    [a.set_xticks(range(6)) for a in ax]\n",
    "    [a.set_yticks(range(6)) for a in ax]\n",
    " \n",
    "    im1 = ax[0].imshow(cmx, vmax=vmax1)\n",
    "    ax[0].set_title('as is')\n",
    "    im2 = ax[1].imshow(cmx_norm, vmax=vmax2)\n",
    "    ax[1].set_title('%')\n",
    "    im3 = ax[2].imshow(cmx_zero_diag, vmax=vmax3)\n",
    "    ax[2].set_title('% and 0 diagonal')\n",
    " \n",
    "    dividers = [make_axes_locatable(a) for a in ax]\n",
    "    cax1, cax2, cax3 = [divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "                        for divider in dividers]\n",
    " \n",
    "    fig.colorbar(im1, cax=cax1)\n",
    "    fig.colorbar(im2, cax=cax2)\n",
    "    fig.colorbar(im3, cax=cax3)\n",
    "    fig.tight_layout()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAx0AAADQCAYAAABiBwxkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3de7QsZX3m8e8jKApeAA+DCBggQYwy4oWgE6MhohEvCWbiGIhBVBJi4i2TrFHUjBgT1yKJl2hidB0DAUeCIGhkEkZhiIZhRtADEuSi4aLIgQOHi1xUhHP5zR9dR5rD7n2r7t61d30/a9XaXW/Xrn57Qz+nfl1vvZWqQpIkSZIm5WFL3QFJkiRJK5tFhyRJkqSJsuiQJEmSNFEWHZIkSZImyqJDkiRJ0kRZdEiSJEmaKIuOZSLJk5L8IMk2S90XSZKkJAcnWTuhfb8uyQVD6z9Iss8kXmsckuyVpJJsu9R96SqLjmWiqr5XVY+uqk1L3RdJK0OSv0ry/SRfTbLHUPtvJvnoUvZN0mjL5bPbHIh/OcmPknwryYsWu6/mGOi6cfZP02XRIUk9lOQg4NnAE4ALgGOb9scB/w3446XrnaRRltln91TgG8DjgXcDZyTZZWm7pKVi0TEFSY5Ncm2Se5JcmeTXhp77mST/muSuJLclOW3EPh502q457Xhds8/vJHnNtN6PpBVhb+CCqroPOA/YMmzh/cBfVtXdS9YzSbNp9dlN8vIk30hyd5Ibkrx36LktxxpHJflec1zy7qHnH5XkpOYsy5XAz83yOk8GngUcV1X3VtWZwDeBXx+x/eOTnNX062vAT2/1fCX5mbneQ/P8a5Ncn+T2JP89yXe3nGVJsl1zpuimZvmrJNs1zx2cZG2SP0qyPsm6JK+fz99Oc7PomI5rgecDjwP+BPh0kt2a5/4UOAfYCdgD+Ou5dpZkB+CjwEur6jHAzwOXTqDfklauK4DnJ3kUcAhwRZIDgf2q6h+WtmuSZtH2s/tD4LXAjsDLgd9L8sqttvkFYL9m/+9J8rNN+3EMioGfBl4CHDXL6zwNuK6q7hlq+7emfSYfA34M7Aa8oVkW/B6SPBX4W+A1zb4eB+w+9LvvBp4LPAM4ADiIB58desLQ7xwNfCzJTnO9ruZm0TEFVfXZqrqpqjZX1WnA1Qz+JwfYAPwU8MSq+nFVXTByRw+2Gdg/yaOqal1VXTGBrktaoarqcuBM4ELgScBfMPgy461J3prk/CSnJNlxKfsp6cHafnar6itV9c3mmOQyBkOgfnGrzf6kOTvxbwwKhQOa9lcD76+qO6rqhuZ1R3k0cNdWbXcBj9l6w2aSnF8H3lNVP2ze48mz/A1mew+vAv5nVV1QVfcD7wFq6NdfA7yvqtZX1a0Mvgw+cuj5Dc3zG6rqbOAHDAqw+f7tNIJFxxQ0p/kuTXJnkjuB/YFVzdNvBwJ8LckVSWar7AGoqh8CvwG8EViX5J+TPGVS/Ze0MlXVh6vqgKr6DQYHE+cz+HfhGAbfcF5FM15cUne0+ewmeU5zcfetSe5icCyxaqvNbh56/CMGBQTAE4Ebhp67fpZu/gB47FZtjwXumWHbXYBt57vvOd7Dg/pYVT8Cbh/69Sdute/rm7Ytbq+qjUPrP3n/8/zbaQSLjglL8lPAJ4E3A4+vqh2ByxkUGlTVzVX1O1X1ROB3gb/dMmZxNlX1pap6MYNTh99qXkOSFizJrgwOVt7H4EuRy6pqA/B14OlL2TdJoy3ys/sPwFnAnlX1OOATNMck87AO2HNo/UmzbHsFsE+S4TMbBzTtW7sV2LiAfc/2HtYxGK4ODK5DYXAh+xY3MRhhMvw6N83yWvN9Xc3BomPydmBwWu9WgOaCpP23PJnkv+SB6e6+32y7ebYdJtk1yWHNtR33Mfg2YdbfkaRZfAh4b/ON4HeAn0vyaOBgwCkqpe5azGf3McAdVfXjDGbC+s0FvN7pwDuT7NQcu7xl1IZV9e8Mrjc9Lskjm0l0ns5gaNjW224CPge8N8n2zXUZs10vMtt7OAP4lSQ/n+QRwHt5cGFwKvDHSXZJsorB8KtPz/nO535dzcGiY8Kq6krgg8BXgVuA/wj836FNfg64KMkPGFTPb5vHPNQPA/6QQWV+B4PxhL835q5L6oEkLwR2rKrPA1TV14B/ZjA84ZeA45ewe5JGaPHZ/X3gfUnuYXDAffoCXvZPGAxH+g6DSXD+xxzbHw4cyOBL1eOBVzXXUczkzQyGMd0MnAT8/Sz7Hfkemmtc3wJ8hsFZjx8A6xl8SQvwZ8Aa4DIGs2ld0rTNR5u/Xe+lqubeSpIkSVpmmjM/dwL7VtV3lro/feaZDkmSJK0YSX6lGaa1A/ABBmc0vru0vZJFh7RASfZsZq+4splx7G1N+18m+VaSy5J8fst0hRncbOneZgazS5N8YmnfgaTlKMmJzQ3LLh9q2znJuUmubn7u1LQnyUeTXNNk0rOWrufS1B3GYAj6TcC+wOHl0J5FGZE7Mx7vzLkv/xtIC9Pc2HG3qrqkmZXjYuCVDGbL+Jeq2pjkzwGq6h1J9gL+qar2H7VPSZpLkhcwGJ/+qS15kuQvGFzYenySY4Gdmtx5GYNx7S8DngN8pKqes1R9l7Q8jcidX2aG45259uWZDmmBmpsxXtI8vofBfOi7V9U5Q3N7X8jQlH2S1FZVnc9g8pBhh/HATdROZvAFyJb2T9XAhcCOzRcmkjRvM+XOYo93th1z3wBYtfM2tdeeD5/Ernvj6qset9RdWNbu3XQ392+6d8a5s1/ySzvU7XdsGvm7F1923xXAj4eaVlfV6pm2bc5iPBO4aKun3gCcNrS+d5JvAHcDf1xV/2eu96CF2XHnbeoJe0wk0npj3RUPuVGwFujuzbffVlW7zPTcOLNnyK5Vta55fDOwa/N4dx58o7W1Tds6NFaPyHb1SHZY6m4saw/bz+xu40c338P9d07+mGeErY93RprIf+W99nw4X/vSnnNvqJFeftDLl7oLy9r/u/nUkc/dfscmvval0fcc2ma3q39cVQfO9RrNjBhnAn9QVXcPtb+bwU2OTmma1gFPqqrbkzwb+MckTxv+HbX3hD225ZNneXKpjT/b/xeWugvL3jk//NTIuyiPK3tGqapK4pjpKXskO/CcHLLU3VjWHvXJXefeSCOd/zujZ+6dZO7McLwzK0tL9U5RbPjJWcHFSfJwBgXHKVX1uaH21wGvAA7ZctFaVd1HMz94VV2c5FrgyQzmCZfUE+PInhnckmS3qlrXDJ9a37TfyIPv7rxH0yapRyaUOzMe78zFazrUOwVsZNPIZS5JApwAXFVVHxpqPxR4O/Crzd1ht7TvkmSb5vE+DGbS8C7PUs+0zZ4RzuKBOzcfBXxhqP21zSxWzwXuGhqGJaknJpE7o4535uKZDvVOUWxqN2vb84AjgW8mubRpexfwUWA74NxBXcKFVfVG4AUM7mC6AdgMvLGqtr4YVNIK1zZ7kpwKHAysSrIWOI7BXZ5PT3I0gztFv7rZ/GwGM1ddA/wIeP3iey5puZpQ7ryTmY93ZmXRod4pYAObF//7VRcAM12wdfaI7c9kMBRLUo+NIXuOGPHUQy4oaIY7vGnRLyZpRZhQ7pywmH1ZdKiXNuO1lpKmz+yRNG1dyR2LDvVOARu8KaakKTN7JE1bl3LHokO9U1Xc35EPoKT+MHskTVuXcseiQ71T0GJ0oyQtjtkjadq6lDsWHeqdImyoGW/cKUkTY/ZImrYu5Y5Fh3pp04yTT0nSZJk9kqatK7lj0aHeGVxU5X0xJU2X2SNp2rqUOxYd6p2iO1W/pP4weyRNW5dyx6JDvTMY37jNUndDUs+YPZKmrUu5Y9Gh3inC/R35AErqD7NH0rR1KXcsOtQ7g+njujG+UVJ/mD2Spq1LuWPRod6p6k7VL6k/zB5J09al3OlG6SNN2WYycplLkj2TfDnJlUmuSPK2pn3nJOcmubr5uVPTniQfTXJNksuSPGvCb09SR7XJHklajK7kjmc61DuD8Y2t/tffCPxRVV2S5DHAxUnOBV4HnFdVxyc5FjgWeAfwUmDfZnkO8PHmp6QeGUP2SNKCdCl3utELaYoGc1Yv/lRjVa0D1jWP70lyFbA7cBhwcLPZycBXGBQdhwGfqqoCLkyyY5Ldmv1I6om22SNJC9Wl3LHoUO8UYdPsIwtXJVkztL66qlbPtGGSvYBnAhcBuw4VEjcDuzaPdwduGPq1tU2bRYfUI/PIHkkaqy7ljkWHemdQ9c/6v/5tVXXgXPtJ8mjgTOAPquru5IGxkVVVSaptXyWtHPPIHkkaqy7lTjd6IU1RETZVu4unkjycQcFxSlV9rmm+ZcuwqSS7Aeub9huBPYd+fY+mTVKPjCN7JGkhupQ73TjfIk1R1aDqH7XMJYNTGicAV1XVh4aeOgs4qnl8FPCFofbXNrNYPRe4y+s5pP5pmz2StFBjOOY5Mcn6JJcPtc04W+dcLDrUO0XYUNuMXObhecCRwAuTXNosLwOOB16c5GrgRc06wNnAdcA1wCeB3x/7m5LUeWPIHklakDHkzknAoVu1Hctgts59gfOa9Tn51Yp6qc1FVVV1AYyc3PqQGbYv4E2LfkFJK0ZXLuiU1B8tj3nObybNGTZqts5ZWXSod7ZU/ZI0TWaPpGmbR+7Me8bOIaNm65yVRYd6p4DN5beNkqbL7JE0bfPInXnN2Dly/wuYrdOiQ73jt42SloLZI2naJpQ7o2brnJVfuaiXNpGRiyRNitkjadomkDujZuuclWc61DtVYcNm/9eXNF1tsyfJfwV+m8GIiW8Crwd2Az4DPB64GDiyqu5v31tJK8EYcudUBheNr0qyFjiOweycpyc5GrgeePV89uWRl3rHIQ6SlkKb7EmyO/BW4KlVdW+S04HDgZcBH66qzyT5BHA08PFx9VnS8tb2mKeqjhjx1ENm65yLw6vUO4OLqjJykaRJGEP2bAs8Ksm2wPbAOuCFwBnN8ycDr5xE3yUtT1065vFMh3rHMx2SlkKb7KmqG5N8APgecC9wDoPhVHdW1cZms7XA7uPoq6SVoUvHPBYd6qXNnuSTtATmyJ6R8+Un2YnBDbn2Bu4EPstD7xIsSQ/RlWMeiw71ThVs2NyND6Ck/phH9sw2X/6LgO9U1a0AST4HPA/YMcm2zdmOPYAbx9lnSctbl455LDrUO1061SipP1pmz/eA5ybZnsHwqkOANcCXgVcxmMFq3lNXSuqHLh3zzKv0SXJokm8nuSbJsZPulDRJbS+qSnJikvVJLh9qOy3Jpc3y3SSXNu17Jbl36LlPTO6drSzmjlaaNtlTVRcxuGD8EgbT5T4MWA28A/jDJNcwmDb3hIm+iR4we7SSLKsLyZNsA3wMeDGDi9S+nuSsqrpy0p2TJiNsbFf1nwT8DfCpLQ1V9Rs/2XvyQeCuoe2vrapntHnBvjF3tDK1y56qOo7BHPnDrgMOatMrPcDs0crT+phnbOZzpuMg4Jqquq654dBnGFzMJi1LVbCpMnKZ+/frfOCOmZ5LEgY3yTl1vL3uHXNHK07b7NFUmD1aUbqUO/MpOnYHbhhan3FKviTHJFmTZM2tt28aV/+ksSvCxs3bjFxoZpAZWo5ZwO6fD9xSVVcPte2d5BtJ/jXJ88f6ZlauBefOnbdvnlrnpMWYR/Zo6S04ezZw39Q6Jy1Ul3JnbBeSN9P6rQY48IBH1rj2K03CZmat7mebQWYuR/DgsxzrgCdV1e1Jng38Y5KnVdXdi9y/hgznzlOevp25o86bI3u0TAxnz2Ozs9mjTutK7syn6LgR2HNo3Sn5tKwVTKS6b+4S/J+BZ//ktarug8HXYFV1cZJrgSczmHVGo5k7WnEmlT0aK7NHK0qXcmc+RcfXgX2T7M3gg3c48JsT7ZU0QVVhY01kzuoXAd+qqrVbGpLsAtxRVZuS7APsy+DCT83O3NGKM8Hs0fiYPVpRupQ7cxYdVbUxyZuBLwHbACdW1RUT75k0QW2miUtyKnAwg2s/1gLHVdUJDP5x2voC8hcA70uyAdgMvLGqZrwIXQ8wd7RSTXuKSi2M2aOVqCu5M69rOqrqbODsCfdFmorBqcbFV/1VdcSI9tfN0HYmcOaiX6zHzB2tNG2zR9Nh9mgl6VLueEdy9U4x/RviSJLZI2naupQ7Fh3qn6Iz4xsl9YjZI2naOpQ7Fh3qnS6dapTUH2aPpGnrUu5YdKh3unSqUVJ/mD2Spq1LuWPRoV7a1JFTjZL6xeyRNG1tcyfJfwV+m8GJk28Cr6+qHy90P6afeqdqMH3cqEWSJsHskTRtbXMnye7AW4EDq2p/BlNJH76YvnimQz0UNnVkfKOkPjF7JE3bWHJnW+BRzT3HtgduWuxOpF4p8B9+SVNn9kiatnnkzqoka4bWV1fV6p/8ftWNST4AfA+4Fzinqs5ZTF8sOtQ/NTjdKElTZfZImra5c+e2qjpw1JNJdgIOA/YG7gQ+m+S3qurTC+2KRYd6p/BiTknTZ/ZImrYx5M6LgO9U1a0AST4H/Dxg0SHNzYs2JS0Fs0fStLXOne8Bz02yPYPhVYcAa2b/lZlZdKiXNm/2H35J02f2SJq2NrlTVRclOQO4BNgIfANYPftvzczzvOqdKqjKyGUuSU5Msj7J5UNt701yY5JLm+VlQ8+9M8k1Sb6d5CUTeluSOq5t9kjSQo0jd6rquKp6SlXtX1VHVtV9i+mLZzrUS5vafdt4EvA3wKe2av9wVX1guCHJUxnMZ/004InA/07y5Kra1KYDkpanltkjSQvWldyx6FDvFGFzi2krq+r8JHvNc/PDgM803wp8J8k1wEHAVxfdAUnLUtvskaSF6lLudKMX0pTVLAvNnNVDyzHz3O2bk1zWDL/aqWnbHbhhaJu1TZukHpojeyRp7LqSO57pUP8U1OynGmeds3qEjwN/Otg7fwp8EHjD4jooaUWaO3skabw6lDsWHeqlcV+0WVW3bHmc5JPAPzWrNwJ7Dm26R9MmqYe8YFzStHUldxxepd4pBtPHjVoWI8luQ6u/BmyZ2eos4PAk2yXZG9gX+Fqb/ktaniaRPZI0my7ljmc61D8tTzUmORU4mMG1H2uB44CDkzxjsHe+C/wuQFVdkeR04EoG81u/yZmrpJ4awzCHJDsCfwfsP9gjbwC+DZwG7MUgf15dVd9v9UKSVgaHV0lLrMXVU1V1xAzNJ8yy/fuB9y/+FSWtGO2v3PwI8MWqelWSRwDbA+8Czquq45McCxwLvKP1K0laGToyU4VFh3oonan6JfVJu+xJ8jjgBcDrAKrqfuD+JIcxOPsKcDLwFSw6JAFdOuax6FD/VHcuqpLUI3Nnz6oka4bWV1fV6qH1vYFbgb9PcgBwMfA2YNeqWtdsczOw6xh7LWk569Axj0WH+qkjH0BJPTN79sw1Xfe2wLOAt1TVRUk+wmAo1QO7r6okHRlMIakTOnLM4+xV6qeu3ClHUr+0y561wNqquqhZP4NBEXLLlhn0mp/rx9tpSctaR455LDrUPwVszuhFkiahZfZU1c3ADUn2a5oOYTAz3lnAUU3bUcAXJtB7SctRh455HF6lXqrNS90DSX00hux5C3BKM3PVdcDrGXyBeHqSo4HrgVe3fhVJK0ZXjnksOtRPHRnfKKlnWmZPVV0KzHTdxyGtdixp5erIMY9Fh/qnIB2p+iX1iNkjado6lDsWHeqhdKbql9QnZo+kaetO7lh0qJ86UvVL6hmzR9K0dSR3nL1K/dOhmRwk9YjZI2naxpA7SXZMckaSbyW5Ksl/WkxXLDrUS6nRy5y/m5yYZH2Sy4fa/rL5MF6W5PNJdmza90pyb5JLm+UTk3tXkrquTfZI0mKMIXc+Anyxqp4CHABctZh+WHSon9rdKOck4NCt2s4F9q+qpwP/Drxz6Llrq+oZzfLGdh2XtKx15CZdknqkRe4keRzwAuAEgKq6v6ruXEw3JnJNx79ftj0veeIzJrHr3vjSTf+81F1Y1g56yV2zPt/mW8WqOj/JXlu1nTO0eiHwqsW/ghbjpm/uwPv2edZSd2NZ++vrz13qLix7P/uk2Z/3jMbKc9/uO3DdWxc12kSNfX7xq0vdhWVtc22c9fk5cmdVkjVD66uravXQ+t7ArcDfJzkAuBh4W1X9cKH99EyH+mfu8Y2rkqwZWo5Z4Cu8AfhfQ+t7J/lGkn9N8vxxvQ1Jy4zXdEiatrlz57aqOnBoWb3VHrYFngV8vKqeCfwQOHYxXXH2KvXSHHNW31ZVM918a+79Ju8GNgKnNE3rgCdV1e1Jng38Y5KnVdXdi9m/pOWtK/PlS+qPlrmzFlhbVRc162ewyKLDMx3qpwmMq07yOuAVwGuqqgCq6r6qur15fDFwLfDkFj2XtJx5TYekaWuRO1V1M3BDkv2apkOAKxfTDc90qHcygbtzJjkUeDvwi1X1o6H2XYA7qmpTkn2AfYHrxvvqkpaDSWSPJM1mTLnzFuCUJI9gcAzz+sXsxKJD/dTi7pxJTgUOZnDtx1rgOAazVW0HnJsE4MJmpqoXAO9LsoHB7XneWFV3tOu8pGWrI3cGltQjLXOnqi4FFjXsfJhFh3qpTdVfVUfM0HzCiG3PBM5c/KtJWkk80yFp2rqSOxYd6ifHT0taCmaPpGnrSO5YdKh/HFctaSmYPZKmrUO5Y9GhXurKB1BSv5g9kqatK7njlLmSJEmSJsozHeqfDp1qlNQjZo+kaetQ7lh0qJ86clGVpJ4xeyRNW0dyx6JDvRO6U/VL6g+zR9K0dSl3LDrUPx061SipR8weSdPWodyx6FA/deRUo6SeMXskTVtHcseiQ73UlapfUr+YPZKmrSu5Y9GhfupI1S+pZ8weSdPWkdyx6FD/dGh8o6QeMXskTVuHcsebA6qfapZlDklOTLI+yeVDbTsnOTfJ1c3PnZr2JPlokmuSXJbkWZN4O5KWiRbZA5BkmyTfSPJPzfreSS5qMua0JI+YTMclLVstc2dcLDrUS9k8epmHk4BDt2o7FjivqvYFzmvWAV4K7NssxwAfH0f/JS1PLbMH4G3AVUPrfw58uKp+Bvg+cPR4eyxpuRtD7oyFRYd6JzX7MpeqOh+4Y6vmw4CTm8cnA68cav9UDVwI7Jhkt/G8E0nLSdvsSbIH8HLg75r1AC8Ezmg2Gc4eSWqdO+Nk0aF+mv1U46oka4aWY+axx12ral3z+GZg1+bx7sANQ9utbdok9VG77Pkr4O3Alu8nHw/cWVUbm3XzRdJDdWR4lReSq5fmOKV4W1UduNh9V1Ul0/7+QNJysNjsSfIKYH1VXZzk4Al0TdIK1ZULyS061E/jLwluSbJbVa1rhk+tb9pvBPYc2m6Ppk1SHy0+e54H/GqSlwGPBB4LfITBkM1tm7Md5oukhxrDMU+SbYA1wI1V9YrF7MPhVeqfmshFVWcBRzWPjwK+MNT+2mYWq+cCdw0Nw5LUJy2yp6reWVV7VNVewOHAv1TVa4AvA69qNhvOHkka5zHP1pNYLJhFh3qpzQcwyanAV4H9kqxNcjRwPPDiJFcDL2rWAc4GrgOuAT4J/P4E3o6kZWICX3i8A/jDJNcwuMbjhHH1VdLK0DZ3tp7EYrEcXqVeanPFRVUdMeKpQ2bYtoA3Lf7VJK0k47jaq6q+AnyleXwdcFD7vUpaqebInVVJ1gytr66q1Vtts2USi8e06YdFh/qneGDuF0maFrNH0rTNnTuzTp4zzkksLDrUO2H6c1NLktkjadrGkDsPmcQiyaer6rcWuiOv6VAvZXONXCRpUsweSdPWJndGTGKx4IIDPNOhPqruzFktqUfMHknT1qHcsehQP/mloqSlYPZImrYx5c7wJBaLYdGhXupK1S+pX8weSdPWldyx6FD/lBdzSloCZo+kaetQ7lh0qHdCd6p+Sf1h9kiati7ljkWH+qk6UvZL6hezR9K0dSR35pwyN8mJSdYnuXwaHZImrpnJYdSibjB7tOKYPZ1n7mjF6VDuzOc+HScBh064H9JUZdPoRZ1xEmaPVhizp/NOwtzRCtOV3JlzeFVVnZ9kr8l3RZqeNhdVJdkPOG2oaR/gPcCOwO8Atzbt76qqsxf/Sv1m9mgl6soFnZqZuaOVqCu5M7ZrOpIcAxwD8Ei2H9dupfErWt39t6q+DTwDIMk2wI3A54HXAx+uqg+Mo5uam7mjZaVl9qg7hrNn2x13WuLeSLPoUO7MZ3jVvFTV6qo6sKoOfDjbjWu30mTULMvCHAJcW1XXj7N7mh9zR8vO+LJHS2g4ex62ww5L3R1pdh3JnbEVHdJykSqyefQCrEqyZmg5ZpbdHQ6cOrT+5iSXNRcj+vWXpJ+YR/ZI0lh1KXcsOtRLc8zkcNuWb7CaZfWM+0geAfwq8Nmm6ePATzMYerUO+ODk34mk5aQrs8hI6o+u5M58psw9FfgqsF+StUmOnny3pMlKjV4W4KXAJVV1C0BV3VJVm6pqM/BJ4KDx97w/zB6tRGPKHk2IuaOVqCu5M5/Zq46YRkekqSlg01g+aUcwNLQqyW5Vta5Z/TXAed5bMHu04owvezQh5o5WnA7ljnckVy+1re6T7AC8GPjdoea/SPIMBh/x7271nCR5RkPS1HUldyw61EttL56qqh8Cj9+q7chWO5W04nnBuKRp60ruWHSof5yeUtJSMHskTVuHcseiQ70TIB0Z3yipP8weSdPWpdyx6FD/dOjunJJ6xOyRNG0dyh3v06EeKqhZFkmaCLNH0rS1y50keyb5cpIrk1yR5G2L7YlnOtRLXan6JfWL2SNp2lrmzkbgj6rqkiSPAS5Ocm5VXbnQHXmmQ/1T3bk7p6QeaZk9o75xTLJzknOTXN383GnSb0XSMtEyd6pqXVVd0jy+B7gK2H0xXbHoUD9trtGLJE1Ku+zZ8o3jU4HnAm9K8lTgWOC8qtoXOK9Zl6SB2XNnVZI1Q8sxo3aTZC/gmcBFi+mGw6vUS9nsKQ1J09cme6pqHbCueXxPki3fOB4GHNxsdjLwFeAdbfopaeWYI3duq6oD59xH8mjgTOAPquruxfTDokP9U4A1h6Rpmzt7ViVZM7S+uqpWz7ThVt847toUJAA3A7u27aqkFWIMxzxJHs6g4Dilqj632P1YdKh3QnmmQ9LUzSN7Flq5XzoAAAUHSURBVPWNY5KfPFdVlcRxopKA9sc8GQTMCcBVVfWhNn3xmg71k9NWSloKLbNnxDeOtyTZrXl+N2D9RPouaXlqlzvPA44EXpjk0mZ52WK64ZkO9U915+6cknqkZfbM8o3jWcBRwPHNzy+06aakFaRl7lTVBQxubN6aRYd6qKDl8Kok3wXuATYBG6vqwCQ7A6cBewHfBV5dVd9v9UKSVpDW2bPlG8dvJrm0aXsXg2Lj9CRHA9cDr27VTUkrSPtjnnGx6FD/FOMaRvVLVXXb0PqWaSuPT3Jss+4MMpIGWmbPHN84HrLoHUtaucZ3zNOaRYd6aULDq5y2UtKsHNopadq6kjteSK5+mv2iqvncKKeAc5JcPPS801ZKmp2TWEiato7kjmc61D9VsKn1tJW/UFU3JvkPwLlJvvXgl3DaSklbmTt7JGm8OpQ7Fh3qp5bVfVXd2Pxcn+TzwEE001ZW1TqnrZQ0I89oSJq2juSOw6vUP8Wg6h+1zCHJDkkes+Ux8MvA5TwwbSU4baWkrbXMHklasA7ljmc61EMFmze12cGuwOebuwBvC/xDVX0xyddx2kpJI7XOHklaoO7kjkWH+qeAza2mrbwOOGCG9ttx2kpJo7TMHklasA7ljkWH+qkjN8qR1DNmj6Rp60juWHSoh5yeUtJSMHskTVt3cseiQ/1TwKZujG+U1CNmj6Rp61DuWHSoh7ozZ7WkPjF7JE1bd3LHokP9U1DVjQ+gpB4xeyRNW4dyx6JD/dSRql9Sz5g9kqatI7lj0aH+qerMTA6SesTskTRtHcodiw71UnXkoipJ/WL2SJq2ruSORYd6qDvTx0nqE7NH0rR1J3cettQdkKZuy/RxoxZJmgSzR9K0jSF3khya5NtJrkly7GK74pkO9U5VdeZUo6T+MHskTVvb3EmyDfAx4MXAWuDrSc6qqisXui+LDvVSbe7GqUZJ/WL2SJq2lrlzEHBNVV0HkOQzwGHAgouO1ATGeSW5Fbh+7Dsen1XAbUvdiWWu63/Dn6qqXWZ6IskXGfR/lNuq6tDJdEuTYu70wnL4G5o9PWP29ELX/4ZtcueRwI+H1ldX1eqh338VcGhV/XazfiTwnKp680I7OZEzHaPeeFckWVNVBy51P5az5fw39B/1lcncWfmW+9/Q7FmZzJ6Vbzn/DbuUO15ILkmSJGkmNwJ7Dq3v0bQtmEWHJEmSpJl8Hdg3yd5JHgEcDpy1mB319ULy1XNvojn4N5QWxs9Me/4NpYXzc9Neb/+GVbUxyZuBLwHbACdW1RWL2ddELiSXJEmSpC0cXiVJkiRpoiw6JEmSJE1Ur4qOcd3Gvc+SnJhkfZLLl7ov0nJh9rRj7kgLZ+60Z/aMV2+KjqHbuL8UeCpwRJKnLm2vlqWTgM7M+Sx1ndkzFidh7kjzZu6MzUmYPWPTm6KDodu4V9X9wJbbuGsBqup84I6l7oe0jJg9LZk70oKZO2Ng9oxXn4qO3YEbhtbXNm2SNElmj6RpM3fUOX0qOiRJkiQtgT4VHWO7jbskLYDZI2nazB11Tp+KjrHdxl2SFsDskTRt5o46pzdFR1VtBLbcxv0q4PTF3sa9z5KcCnwV2C/J2iRHL3WfpC4ze9ozd6SFMXfGw+wZr1TVUvdBkiRJ0grWmzMdkiRJkpaGRYckSZKkibLokCRJkjRRFh2SJEmSJsqiQ5IkSdJEWXRIkiRJmiiLDkmSJEkT9f8B3KkOhvZ+tKsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x216 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cmx_svm = confusion_matrix(y_test, best_pred)\n",
    "\n",
    "\n",
    "plot_confusion_matrix(cmx_svm, vmax1=225, vmax2=100, vmax3=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
