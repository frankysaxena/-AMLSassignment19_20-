{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from scipy import misc\n",
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.svm import SVC \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "import gc\n",
    "\n",
    "# path = '/Users/fsaxena/Documents/UCL/Masters/IntroML1/AMLSassignment19_20/AMLS_19-20_SN14002056'\n",
    "path = '/home/fsaxena/amls/AMLSassignment19_20/AMLS_19-20_SN14002056'\n",
    "\n",
    "\n",
    "assignment_celeb = 'celeba'\n",
    "assignment_cartoon = 'cartoon_set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(path_to_root, assignment):\n",
    "    return pd.read_csv(path_to_root + '/Datasets/original_dataset_AMLS_19-20/' + assignment + '/labels.csv', sep='\\t')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_to_vector_and_resize(file):\n",
    "    img = cv2.imread(file, cv2.IMREAD_UNCHANGED)\n",
    "    scale_percent = 35 # percent of original size\n",
    "    width = int(img.shape[1] * scale_percent / 100)\n",
    "    height = int(img.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    # resize image\n",
    "    resized_img = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_img=path+'/Datasets/original_dataset_AMLS_19-20/'+assignment_cartoon+'/img/1.png'\n",
    "path_pre_img = path+'/Datasets/original_dataset_AMLS_19-20/'+assignment_cartoon+'/img/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now need to add each raw pic to each part of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  eye_color  face_shape file_name\n",
      "0              0          1           4     0.png\n",
      "1              1          2           4     1.png\n",
      "2              2          2           3     2.png\n",
      "3              3          2           0     3.png\n",
      "4              4          0           2     4.png\n",
      "...          ...        ...         ...       ...\n",
      "9995        9995          3           2  9995.png\n",
      "9996        9996          0           3  9996.png\n",
      "9997        9997          1           2  9997.png\n",
      "9998        9998          0           2  9998.png\n",
      "9999        9999          2           2  9999.png\n",
      "\n",
      "[10000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "cartoon_dataframe = data_loader(path, assignment_cartoon)\n",
    "print(cartoon_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_Array = []\n",
    "toTensor = torchvision.transforms.ToTensor()\n",
    "\n",
    "for img_name in cartoon_dataframe['file_name']:\n",
    "    img_vec = np.array(convert_image_to_vector_and_resize(path_pre_img + img_name))\n",
    "    vec_Array.append(img_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dataset = vec_Array\n",
    "y_dataset = np.array(cartoon_dataframe['eye_color'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "x, X_test, y, y_test = train_test_split(\n",
    "    x_dataset,\n",
    "    y_dataset,\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "X_train = np.reshape(X_train, (8000, 122500))\n",
    "X_test = np.reshape(X_test, (2000, 122500))\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelName='DTree'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,9):\n",
    "    depth = i\n",
    "    dtree_model = DecisionTreeClassifier(max_depth = i).fit(X_train, y_train) \n",
    "    dtree_predictions = dtree_model.predict(X_test) \n",
    "\n",
    "    labels = np.array(['0', '1', '2', '3', '4'])\n",
    "\n",
    "\n",
    "\n",
    "    dsp = plot_confusion_matrix(dtree_model, X_test, y_test, display_labels=labels, normalize='true')\n",
    "\n",
    "    plt.title(\"B2: Confusion Matrix w/ \" + modelName +  \", Depth: \" + str(depth))\n",
    "\n",
    "    accuracy_score = 100*np.sum(dtree_model.predict(X_test) == y_test)/len(y_test)\n",
    "    accuracies_plot = []\n",
    "    accuracies_plot.append(accuracy_score)\n",
    "    \n",
    "    print('Percentage correct: ', accuracy_score)\n",
    "\n",
    "    with open('B2/Confusion_Matrix'+modelName + '_depth_'+str(depth) + '.png', 'wb') as dsp:\n",
    "        plt.savefig(dsp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B2_accuracies_decision_tree = [ 35.75,51.85,66.85,83.25,83.25,83.5,84.0,84.5 ]\n",
    "B2_dt_depth = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "plt.xlabel('Decision Tree Depth')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('B2: Comparison of increasing depth to accuracy score')\n",
    "plt.plot(B2_dt_depth, B2_accuracies_decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
