{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from scipy import misc\n",
    "import cv2\n",
    "import numpy as np \n",
    "\n",
    "# path = '/Users/fsaxena/Documents/UCL/Masters/IntroML1/AMLSassignment19_20/AMLS_19-20_SN14002056'\n",
    "path = '/home/fsaxena/amls/AMLSassignment19_20/AMLS_19-20_SN14002056'\n",
    "\n",
    "\n",
    "assignment_celeb = 'celeba'\n",
    "assignment_cartoon = 'cartoon_set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(path_to_root, assignment):\n",
    "    return pd.read_csv(path_to_root + '/Datasets/original_dataset_AMLS_19-20/' + assignment + '/labels.csv', sep='\\t')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_image_to_vector(file):\n",
    "    img = cv2.imread(file)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_img=path+'/Datasets/original_dataset_AMLS_19-20/'+assignment_celeb+'/img/0.jpg'\n",
    "path_pre_img = path+'/Datasets/original_dataset_AMLS_19-20/'+assignment_celeb+'/img/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, 178, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(convert_image_to_vector(path_to_img))\n",
    "convert_image_to_vector(path_to_img).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now need to add each raw pic to each part of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  img_name  gender  smiling\n",
      "0              0     0.jpg      -1        1\n",
      "1              1     1.jpg      -1        1\n",
      "2              2     2.jpg       1       -1\n",
      "3              3     3.jpg      -1       -1\n",
      "4              4     4.jpg      -1       -1\n",
      "...          ...       ...     ...      ...\n",
      "4995        4995  4995.jpg       1        1\n",
      "4996        4996  4996.jpg       1        1\n",
      "4997        4997  4997.jpg       1        1\n",
      "4998        4998  4998.jpg       1        1\n",
      "4999        4999  4999.jpg       1        1\n",
      "\n",
      "[5000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "celeb_dataframe = data_loader(path, assignment_celeb)\n",
    "print(celeb_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_Array = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_name in celeb_dataframe['img_name']:\n",
    "    img_vec = np.array(convert_image_to_vector(path_pre_img + img_name))\n",
    "    vec_Array.append(img_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Dict = {\n",
    "    'img_vec': vec_Array,\n",
    "    'gender': celeb_dataframe['gender']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dataset = vec_Array\n",
    "y_dataset = np.array(data_Dict['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(data_Dict, columns = ['img_vec', 'gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "x, X_test, y, y_test = train_test_split(\n",
    "    x_dataset,\n",
    "    y_dataset,\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x\n",
    "y_train = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_val, y_train, y_val = train_test_split(\n",
    "#     x,\n",
    "#     y,\n",
    "#     test_size=0.25,\n",
    "#     shuffle=True,\n",
    "#     random_state=42,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage import color\n",
    "\n",
    "from skimage.feature import hog\n",
    "from skimage.io import imread\n",
    "from skimage.transform import rescale\n",
    " \n",
    "class RGB2GrayTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Convert an array of RGB images to grayscale\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self):\n",
    "        pass\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"returns itself\"\"\"\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"perform the transformation and return an array\"\"\"\n",
    "        return np.array([color.rgb2gray(img) for img in X])\n",
    " \n",
    " \n",
    "class HogTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Expects an array of 2d arrays (1 channel images)\n",
    "    Calculates hog features for each img\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self, y=None, orientations=9,\n",
    "                 pixels_per_cell=(8, 8),\n",
    "                 cells_per_block=(3, 3), block_norm='L2-Hys'):\n",
    "        self.y = y\n",
    "        self.orientations = orientations\n",
    "        self.pixels_per_cell = pixels_per_cell\n",
    "        self.cells_per_block = cells_per_block\n",
    "        self.block_norm = block_norm\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    " \n",
    "        def local_hog(X):\n",
    "            return hog(X,\n",
    "                       orientations=self.orientations,\n",
    "                       pixels_per_cell=self.pixels_per_cell,\n",
    "                       cells_per_block=self.cells_per_block,\n",
    "                       block_norm=self.block_norm)\n",
    " \n",
    "        try: # parallel\n",
    "            return np.array([local_hog(img) for img in X])\n",
    "        except:\n",
    "            return np.array([local_hog(img) for img in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance of each transformer\n",
    "grayify = RGB2GrayTransformer()\n",
    "hogify = HogTransformer(\n",
    "    pixels_per_cell=(8, 8),\n",
    "    cells_per_block=(2,2),\n",
    "    orientations=9,\n",
    "    block_norm='L2-Hys'\n",
    ")\n",
    "scalify = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 19656)\n"
     ]
    }
   ],
   "source": [
    "# call fit_transform on each transform converting X_train step by step\n",
    "X_train_gray = grayify.fit_transform(X_train)\n",
    "X_train_hog = hogify.fit_transform(X_train_gray)\n",
    "X_train_prepared = scalify.fit_transform(X_train_hog)\n",
    " \n",
    "print(X_train_prepared.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',\n",
       "              power_t=0.5, random_state=42, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_clf = SGDClassifier(random_state=42, max_iter=1000, tol=1e-3, n_jobs = -1)\n",
    "sgd_clf.fit(X_train_prepared, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_val_gray = grayify.transform(X_val)\n",
    "# X_val_hog = hogify.transform(X_val_gray)\n",
    "# X_val_prepared = scalify.transform(X_val_hog)\n",
    "\n",
    "X_test_gray = grayify.transform(X_test)\n",
    "X_test_hog = hogify.transform(X_test_gray)\n",
    "X_test_prepared = scalify.transform(X_test_hog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True False False  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True]\n",
      "\n",
      "Percentage correct:  92.5\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = sgd_clf.predict(X_test_prepared)\n",
    "print(np.array(y_test_pred == y_test)[:25])\n",
    "print('')\n",
    "print('Percentage correct: ', 100*np.sum(y_test_pred == y_test)/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage correct:  92.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    " \n",
    "HOG_pipeline = Pipeline([\n",
    "    ('grayify', RGB2GrayTransformer()),\n",
    "    ('hogify', HogTransformer(\n",
    "        pixels_per_cell=(8, 8),\n",
    "        cells_per_block=(2,2),\n",
    "        orientations=9,\n",
    "        block_norm='L2-Hys')\n",
    "    ),\n",
    "    ('scalify', StandardScaler()),\n",
    "    ('classify', SGDClassifier(random_state=42, max_iter=1000, tol=1e-3))\n",
    "])\n",
    " \n",
    "clf = HOG_pipeline.fit(X_train, y_train)\n",
    "print('Percentage correct: ', 100*np.sum(clf.predict(X_test) == y_test)/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    " \n",
    "param_grid = [\n",
    "    {'hogify__orientations': [9],\n",
    "    'hogify__cells_per_block': [(3, 3)],\n",
    "    'hogify__pixels_per_cell': [(8, 8), (14, 14)]},\n",
    "    {'hogify__orientations': [9],\n",
    "     'hogify__cells_per_block': [(3, 3)],\n",
    "     'hogify__pixels_per_cell': [(14, 14)],\n",
    "     'classify': [\n",
    "         SGDClassifier(random_state=42, max_iter=1000, tol=1e-3),\n",
    "         svm.SVC(kernel='linear')]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  12 | elapsed:  3.6min remaining:   42.9s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:  3.8min finished\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(HOG_pipeline,\n",
    "                           param_grid,\n",
    "                           cv=3,\n",
    "                           n_jobs=-1,\n",
    "                           scoring='accuracy',\n",
    "                           verbose=1,\n",
    "                           return_train_score=True)\n",
    " \n",
    "grid_res = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('grayify', RGB2GrayTransformer()),\n",
       "                ('hogify',\n",
       "                 HogTransformer(block_norm='L2-Hys', cells_per_block=(3, 3),\n",
       "                                orientations=9, pixels_per_cell=(8, 8),\n",
       "                                y=None)),\n",
       "                ('scalify',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('classify',\n",
       "                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
       "                               fit_intercept=True, l1_ratio=0.15,\n",
       "                               learning_rate='optimal', loss='hinge',\n",
       "                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "                               penalty='l2', power_t=0.5, random_state=42,\n",
       "                               shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "                               verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_res.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9035008002375408"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_res.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hogify__cells_per_block': (3, 3),\n",
       " 'hogify__orientations': 9,\n",
       " 'hogify__pixels_per_cell': (8, 8)}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_res.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage correct:  92.9\n"
     ]
    }
   ],
   "source": [
    "best_pred = grid_res.predict(X_test)\n",
    "print('Percentage correct: ', 100*np.sum(best_pred == y_test)/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
